{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import talib\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pytz\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16dfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL SETTINGS\n",
    "\n",
    "# Data directories\n",
    "#coin_dataDir = 'DATA/TESTDIR/' # Debug dir for testing I/O logic and/or issues. It should be a clone of the above dir.\n",
    "coin_dataDir = 'DATA/COMBINEDDATA/'\n",
    "plot_dataDir = 'DATA/INITIAL_INSIGHTS/MOMENTUM_FACTORS/'\n",
    "model_dataDir = 'DATA/MODELDATA/'\n",
    "riskFactor_dataDir = 'DATA/RISKFACTORSDATA/'\n",
    "\n",
    "\n",
    "\n",
    "isdir = os.path.isdir(model_dataDir)\n",
    "\n",
    "# Date ranges\n",
    "START = 2019\n",
    "END = 2022\n",
    "\n",
    "MONTH = 30\n",
    "YEAR = 12 * MONTH\n",
    "\n",
    "# Helpers\n",
    "idx = pd.IndexSlice\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# END GLOBAL SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in MDF with initial coin pool\n",
    "cpool_mdf = pd.read_csv(coin_dataDir + 'CoinPool.csv')\n",
    "cpool_mdf.rename(columns={'Unnamed: 0': 'Dates'}, inplace=True)\n",
    "cpool_mdf['Dates'] = pd.to_datetime(cpool_mdf['Dates'])\n",
    "cpool_mdf.set_index(['Dates', 'Coin'], inplace=True)\n",
    "print('Initial Base Data:'.upper())\n",
    "print(cpool_mdf.info())\n",
    "\n",
    "\n",
    "ohlcv = ['Open','High','Low','Close','Volume']\n",
    "prices_mdf = (cpool_mdf\n",
    "              .loc[idx[str(START):str(END), :], ohlcv]\n",
    "              .swaplevel()\n",
    "              .sort_index())\n",
    "\n",
    "# want at least X years of data\n",
    "yr = 3\n",
    "min_obs = yr * YEAR\n",
    "\n",
    "# have this much per ticker\n",
    "nobs = prices_mdf.groupby(level='Coin').size()\n",
    "\n",
    "# keep those that exceed the limit\n",
    "keep = nobs[nobs > min_obs].index\n",
    "\n",
    "prices_mdf = prices_mdf.loc[idx[keep, :], :]\n",
    "print(f\"After dropping coins with less than {yr} years of data\".upper())\n",
    "print(prices_mdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472ab0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Technical Analysis Indicators to be use as momentum alpha factors (The Features)\n",
    "\n",
    "# Relative Strength Index (RSI)\n",
    "prices_mdf['RSI'] = prices_mdf.groupby(level='Coin').Close.apply(talib.RSI)\n",
    "\n",
    "# Bollinger Bands\n",
    "def compute_bb(close):\n",
    "    high, mid, low = talib.BBANDS(close, timeperiod=20)\n",
    "    return pd.DataFrame({'BB_high': high, 'BB_low': low}, index=close.index)\n",
    "\n",
    "prices_mdf = (prices_mdf.join(prices_mdf\n",
    "                      .groupby(level='Coin')\n",
    "                      .Close\n",
    "                      .apply(compute_bb)))\n",
    "\n",
    "# Average True Range (ATR)\n",
    "def compute_atr(coin_data):\n",
    "    df = talib.ATR(coin_data.High, coin_data.Low,\n",
    "             coin_data.Close, timeperiod=14)\n",
    "    return df.sub(df.mean()).div(df.std())\n",
    "\n",
    "prices_mdf['ATR'] = (prices_mdf.groupby('Coin', group_keys=False)\n",
    "                 .apply(compute_atr))\n",
    "\n",
    "# Moving Average Convergence Divergence (MACD)\n",
    "def compute_macd(close):\n",
    "    macd = talib.MACD(close)[0]\n",
    "    return (macd - np.mean(macd))/np.std(macd)\n",
    "\n",
    "prices_mdf['MACD'] = (prices_mdf\n",
    "                  .groupby('Coin', group_keys=False)\n",
    "                  .Close\n",
    "                  .apply(compute_macd))\n",
    "\n",
    "\n",
    "# Stochastic Oscillator (STOCH)\n",
    "def compute_stoch(coin_data):\n",
    "    slowk, slowd = talib.STOCH(coin_data.High,\n",
    "                         coin_data.Low,\n",
    "                         coin_data.Close,\n",
    "                         fastk_period=14,\n",
    "                         slowk_period=3,\n",
    "                         slowk_matype=0,\n",
    "                         slowd_period=3,\n",
    "                         slowd_matype=0)\n",
    "\n",
    "    return slowd/slowk\n",
    "\n",
    "prices_mdf['STOCH'] = (prices_mdf\n",
    "                       .groupby('Coin', group_keys=False)\n",
    "                       .apply(compute_stoch))\n",
    "\n",
    "# Average Directional Index (ADX)\n",
    "def compute_adx(coin_data):\n",
    "    real = talib.ADX(coin_data.High,\n",
    "                     coin_data.Low,\n",
    "                     coin_data.Close,\n",
    "                     timeperiod=14)\n",
    "\n",
    "    return real\n",
    "\n",
    "prices_mdf['ADX'] = (prices_mdf\n",
    "                     .groupby('Coin', group_keys=False)\n",
    "                     .apply(compute_adx))\n",
    "\n",
    "\n",
    "#Plus/Minus Directional Index\n",
    "def compute_diplus(coin_data):\n",
    "    real = talib.PLUS_DI(coin_data.High,\n",
    "                     coin_data.Low,\n",
    "                     coin_data.Close,\n",
    "                     timeperiod=14)\n",
    "\n",
    "    return real\n",
    "\n",
    "def compute_diminus(coin_data):\n",
    "    real = talib.MINUS_DI(coin_data.High,\n",
    "                     coin_data.Low,\n",
    "                     coin_data.Close,\n",
    "                     timeperiod=14)\n",
    "\n",
    "    return real\n",
    "\n",
    "prices_mdf[\"DI_PLUS\"] = (prices_mdf.groupby('Coin', group_keys=False).apply(compute_diplus))\n",
    "prices_mdf[\"DI_MINUS\"] = (prices_mdf.groupby('Coin', group_keys=False).apply(compute_diminus))\n",
    "\n",
    "# Compute lagged returns and Winsorize\n",
    "lags = [1, 7, 14, 30, 60, 90]\n",
    "q = 0.0001\n",
    "\n",
    "for lag in lags:\n",
    "    prices_mdf[f'return_{lag}d'] = (prices_mdf.groupby(level='Coin').Close\n",
    "                                .pct_change(lag)\n",
    "                                .pipe(lambda x: x.clip(lower=x.quantile(q),\n",
    "                                                       upper=x.quantile(1 - q)))\n",
    "                                .add(1)\n",
    "                                .pow(1 / lag)\n",
    "                                .sub(1)\n",
    "                                )\n",
    "# Shift lagged returns\n",
    "for t in [1, 2, 3, 4, 5]:\n",
    "    for lag in [1, 7, 14, 30, 60, 90]:\n",
    "        prices_mdf[f'return_{lag}d_lag{t}'] = (prices_mdf.groupby(level='Coin')\n",
    "                                           [f'return_{lag}d'].shift(t * lag))\n",
    "\n",
    "# Generate target forward returns\n",
    "for t in [1, 7, 14, 30, 60, 90]:\n",
    "    prices_mdf[f'target_{t}d'] = prices_mdf.groupby(level='Coin')[f'return_{t}d'].shift(-t)\n",
    "\n",
    "# Create dummy time variables. USe drop first to avoid creating multicollinearity.\n",
    "prices_mdf['year'] = prices_mdf.index.get_level_values('Dates').year\n",
    "prices_mdf['month'] = prices_mdf.index.get_level_values('Dates').month\n",
    "\n",
    "prices_mdf = pd.get_dummies(prices_mdf,\n",
    "                        columns=['year', 'month'],\n",
    "                        prefix=['year', 'month'],\n",
    "                        prefix_sep=['_', '_'],\n",
    "                        drop_first=True)\n",
    "\n",
    "\n",
    "# Read in PCA Risk Factors\n",
    "risk_factors_df = pd.read_csv(riskFactor_dataDir + 'PCA_Risk_Factors.csv')\n",
    "risk_factors_df.rename(columns={'Unnamed: 0': 'Dates'}, inplace=True)\n",
    "risk_factors_df['Dates'] = risk_factors_df['Dates'].astype('datetime64')\n",
    "risk_factors_df = risk_factors_df.set_index('Dates')\n",
    "risk_factors_df.drop(risk_factors_df.index[-1], inplace=True)\n",
    "\n",
    "# Combine them with daily returns\n",
    "daily_returns = prices_mdf.loc[:, 'return_1d':'return_90d']\n",
    "factor_betas = daily_returns.join(risk_factors_df).sort_index()\n",
    "\n",
    "# Get rid of the extra returns\n",
    "del factor_betas['return_7d']\n",
    "del factor_betas['return_14d']\n",
    "del factor_betas['return_30d']\n",
    "del factor_betas['return_60d']\n",
    "del factor_betas['return_90d']\n",
    "\n",
    "# Compute the factor Betas with Rolling OLS Regression on the PCA Principal Componenets\n",
    "T = 30\n",
    "betas = (factor_betas.groupby(level='Coin',\n",
    "                             group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x.return_1d,\n",
    "                                     exog=sm.add_constant(x.drop('return_1d', axis=1)),\n",
    "                                     window=min(T, x.shape[0]-1))\n",
    "                .fit(params_only=True)\n",
    "                .params\n",
    "                .drop('const', axis=1)))\n",
    "\n",
    "\n",
    "factors = ['Principal Component 1', 'Principal Component 2', 'Principal Component 3',\n",
    "           'Principal Component 4']\n",
    "\n",
    "# Impute missing Betas\n",
    "betas = betas.loc[:, factors] = betas.groupby('Coin')[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "print(\"Factos Betas:\".upper())\n",
    "print(betas.describe().join(betas.sum(1).describe().to_frame('total')))\n",
    "\n",
    "# Combine the Factor Betas with the rest of the model\n",
    "prices_mdf = (prices_mdf\n",
    "        .join(betas\n",
    "              .groupby(level='Coin')\n",
    "              .shift()))\n",
    "\n",
    "# Immpute the missing factor betas to fill things out\n",
    "prices_mdf.loc[:, factors] = prices_mdf.groupby('Coin')[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "print(\"Features so far\".upper())\n",
    "print(prices_mdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model data\n",
    "if isdir == False:\n",
    "    os.makedirs(model_dataDir)\n",
    "    print(\"Directory '% s' created\" % model_dataDir)\n",
    "    prices_mdf.to_hdf(f'{model_dataDir}model_data.h5', 'model_data')\n",
    "    prices_mdf.to_csv(f'{model_dataDir}ModelData.csv')\n",
    "    print(f\"The model data has been saved to {model_dataDir} as a MultiIndex dataframe\")\n",
    "\n",
    "else:\n",
    "    prices_mdf.to_csv(f'{model_dataDir}ModelData.csv')\n",
    "    prices_mdf.to_hdf(f'{model_dataDir}model_data.h5', 'model_data')\n",
    "    print(f\"The model data has been saved to {model_dataDir} as a MultiIndex dataframe\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3463d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET INSIGHTS AND VISUALIZATION PLOTS\n",
    "\n",
    "# Plot correlation custermap of the Betas\n",
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "beta_cmap = sns.clustermap(betas.corr(), annot=True, cmap=cmap, center=0)\n",
    "\n",
    "# Correlation Cluster map of the Returns\n",
    "returns = prices_mdf.loc[:, 'return_1d':\"return_90d\"]\n",
    "clusterMap = sns.clustermap(returns.corr('spearman'), annot=True, center=0, cmap='Blues')\n",
    "print('Coins with Unique Values:')\n",
    "print(returns.index.get_level_values('Coin').nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d48312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check return distributions\n",
    "\n",
    "sns_distPlot = sns.distplot(returns['return_90d'])\n",
    "fig = sns_distPlot.get_figure()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_distPlot = sns.distplot(returns['return_60d'])\n",
    "fig = sns_distPlot.get_figure()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05464e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_distPlot = sns.distplot(returns['return_30d'])\n",
    "fig = sns_distPlot.get_figure()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_distPlot = sns.distplot(returns['return_14d'])\n",
    "fig = sns_distPlot.get_figure()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c42117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_distPlot = sns.distplot(returns['return_7d'])\n",
    "fig = sns_distPlot.get_figure()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_distPlot = sns.distplot(returns['return_1d'])\n",
    "fig = sns_distPlot.get_figure()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf75638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman Ranks and scatter plots for factors\n",
    "target = 'target_7d'\n",
    "price_copy = prices_mdf.copy()\n",
    "\n",
    "# Daily Returns\n",
    "daily_target = \"target_1d\"\n",
    "metric = 'return_1d'\n",
    "j=sns.jointplot(x=metric, y=daily_target, data=price_copy)\n",
    "df = price_copy[[metric, daily_target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[daily_target])\n",
    "print(\"Daily Returns Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Returns\n",
    "daily_target = \"target_7d\"\n",
    "metric = 'return_7d'\n",
    "j=sns.jointplot(x=metric, y=daily_target, data=price_copy)\n",
    "df = price_copy[[metric, daily_target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[daily_target])\n",
    "print(\"Weekly Returns Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaf80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-Weekly Returns\n",
    "daily_target = \"target_14d\"\n",
    "metric = 'return_14d'\n",
    "j=sns.jointplot(x=metric, y=daily_target, data=price_copy)\n",
    "df = price_copy[[metric, daily_target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[daily_target])\n",
    "print(\"Bi-Weekly Returns Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098af529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Returns\n",
    "daily_target = \"target_30d\"\n",
    "metric = 'return_30d'\n",
    "j=sns.jointplot(x=metric, y=daily_target, data=price_copy)\n",
    "df = price_copy[[metric, daily_target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[daily_target])\n",
    "print(\"Monthly Returns Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-Monthly Returns\n",
    "daily_target = \"target_60d\"\n",
    "metric = 'return_60d'\n",
    "j=sns.jointplot(x=metric, y=daily_target, data=price_copy)\n",
    "df = price_copy[[metric, daily_target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[daily_target])\n",
    "print(\"Bi-Monthly Returns Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three Month Returns\n",
    "daily_target = \"target_90d\"\n",
    "metric = 'return_90d'\n",
    "j=sns.jointplot(x=metric, y=daily_target, data=price_copy)\n",
    "df = price_copy[[metric, daily_target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[daily_target])\n",
    "print(\"Three Month Returns Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07280ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Strength Index (RSI)\n",
    "print(\"Daily RETURNS FEATURE INFO\")\n",
    "price_copy.loc[:, 'rsi_signal'] = pd.cut(price_copy.RSI, bins=[0, 30, 70, 100])\n",
    "print(\"RSI Distributions\")\n",
    "print(price_copy.groupby('rsi_signal')['target_7d'].describe().to_string())\n",
    "\n",
    "metric = \"RSI\"\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"RSI Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Directional Moving Index (ADX)\n",
    "print(\"ADX FEATURE INFO\")\n",
    "price_copy.loc[:, 'adx_signal'] = pd.cut(price_copy.ADX, bins=[0, 25, 50, 75, 100])\n",
    "print(\"ADX Distributions\")\n",
    "print(price_copy.groupby('adx_signal')['target_7d'].describe().to_string())\n",
    "\n",
    "metric = \"ADX\"\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"ADX Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directional Indices (DM+/-)\n",
    "metric = \"DI_PLUS\"\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"DI Plus Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"DI_MINUS\"\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"DI Minus Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Bands\n",
    "metric = 'BB_low'\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"Lower BB Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf57bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'BB_high'\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"Upper BB Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active True Range (ATR)\n",
    "metric = 'ATR'\n",
    "j=sns.jointplot(x=metric, y=target, data=price_copy)\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"ATR Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd63ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average Convegeance Divergeance (MACD)\n",
    "metric = 'MACD'\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"MACD Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Oscillator\n",
    "metric = 'STOCH'\n",
    "df = price_copy[[metric, target]].dropna()\n",
    "r, p = spearmanr(df[metric], df[target])\n",
    "print(\"STOCH Spearman\")\n",
    "print(f'{r:,.2%} ({p:.2%})')\n",
    "j=sns.jointplot(x=df[metric], y=df[target], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd7c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots and statistics\n",
    "print(\"RETURNS PERCENTILES\")\n",
    "returns = prices_mdf.groupby(level='Coin').Close.pct_change()\n",
    "percentiles=[.0001, .001, .01]\n",
    "percentiles+= [1-p for p in percentiles]\n",
    "print(returns.describe(percentiles=percentiles).iloc[2:].to_frame('percentiles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI distplot\n",
    "RSI_ax = sns.distplot(prices_mdf.RSI.dropna())\n",
    "RSI_ax.axvline(30, ls='--', lw=1, c='k')\n",
    "RSI_ax.axvline(70, ls='--', lw=1, c='k')\n",
    "RSI_ax.set_title('RSI Distribution with Signal Threshold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea47c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Bands distplot\n",
    "prices_mdf['BB_high'] = prices_mdf.BB_high.sub(prices_mdf.Close).div(prices_mdf.BB_high).apply(np.log1p)\n",
    "prices_mdf['BB_low'] = prices_mdf.Close.sub(prices_mdf.BB_low).div(prices_mdf.Close).apply(np.log1p)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "sns.distplot(prices_mdf.BB_low.dropna(), ax=axes[0])\n",
    "sns.distplot(prices_mdf.BB_high.dropna(), ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149639f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average True Range\n",
    "atr_plot = sns.distplot(prices_mdf.ATR.dropna())\n",
    "fig = atr_plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD distribution\n",
    "print(\"MACD Percentiles\")\n",
    "print(prices_mdf\n",
    "      .MACD\n",
    "      .describe(percentiles=[.001, .01, .02, .03, .04, .05, .95, .96, .97, .98, .99, .999])\n",
    "      .apply(lambda x: f'{x:,.1f}'))\n",
    "\n",
    "MACD_dist = sns.distplot(prices_mdf.MACD.dropna())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADX distribution plot\n",
    "ADX_dist = sns.distplot(prices_mdf.ADX.dropna())\n",
    "ADX_dist.axvline(25, ls='--', lw=1, c='k')\n",
    "ADX_dist.axvline(50, ls='--', lw=1, c='k')\n",
    "ADX_dist.axvline(75, ls='--', lw=1, c='k')\n",
    "ADX_dist.set_title('ADX Distribution with Signal Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Oscillator distplot\n",
    "print(\"STOCH percentiles\")\n",
    "print(prices_mdf\n",
    "      .STOCH\n",
    "      .describe(percentiles=[.001, .01, .02, .03, .04, .05, .95, .96, .97, .98, .99, .999])\n",
    "      .apply(lambda x: f'{x:,.1f}'))\n",
    "\n",
    "\n",
    "\n",
    "STOCH_ax = sns.distplot(prices_mdf.STOCH.dropna())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directional Indicators (DI +/-)\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "sns.distplot(prices_mdf.DI_PLUS.dropna(), ax=axes[0])\n",
    "sns.distplot(prices_mdf.DI_MINUS.dropna(), ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_mdf = (prices_mdf\n",
    "            .dropna()\n",
    "            .drop(['Open', 'Close', 'Low', 'High', 'Volume'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual Information of the Data\n",
    "target_labels = [f'target_{i}d' for i in [1,7,14,30,60,90]]\n",
    "targets = prices_mdf.dropna().loc[:, target_labels]\n",
    "\n",
    "features = prices_mdf.dropna().drop(labels=target_labels, axis=1)\n",
    "#print(features.columns)\n",
    "cat_cols = ['year_2021','year_2022', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
    "       'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n",
    "discrete_features = [features.columns.get_loc(c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = pd.DataFrame()\n",
    "for label in target_labels:\n",
    "    mi = mutual_info_classif(X=features, \n",
    "                             y=(targets[label]> 0).astype(int),\n",
    "                             discrete_features=discrete_features,\n",
    "                             random_state=42\n",
    "                            )\n",
    "    mutual_info[label] = pd.Series(mi, index=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f530ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d12ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Mutual Information(MI) Heatmap\n",
    "fig, ax= plt.subplots(figsize=(15, 4))\n",
    "sns.heatmap(mutual_info.div(mutual_info.sum()).T, ax=ax, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(prices_mdf,\n",
    "                            columns=['year_2021', 'year_2022', 'month_2', 'month_3', 'month_4', 'month_5',\n",
    "       'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n",
    "       'month_12'])\n",
    "dummy_data = dummy_data.rename(columns={c:c.replace('.0', '') for c in dummy_data.columns})\n",
    "dummy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Data\n",
    "target_labels = [f'target_{i}d' for i in [1,7,14,30,60,90]]\n",
    "dummy_targets = dummy_data.dropna().loc[:, target_labels]\n",
    "\n",
    "dummy_features = dummy_data.dropna().drop(target_labels, axis=1)\n",
    "cat_cols = [c for c in dummy_features.columns if c not in features.columns]\n",
    "discrete_features = [dummy_features.columns.get_loc(c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_dummies = pd.DataFrame()\n",
    "for label in target_labels:\n",
    "    mi = mutual_info_classif(X=dummy_features, \n",
    "                             y=(dummy_targets[label]> 0).astype(int),\n",
    "                             discrete_features=discrete_features,\n",
    "                             random_state=42\n",
    "                            )    \n",
    "    mutual_info_dummies[label] = pd.Series(mi, index=dummy_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_dummies.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Normalized Mutual Information(MI) Heatmap\n",
    "fig, ax= plt.subplots(figsize=(4, 20))\n",
    "sns.heatmap(mutual_info_dummies.div(mutual_info_dummies.sum()), ax=ax, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4652b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
