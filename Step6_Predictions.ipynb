{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5f6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04031cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL SETTINGS\n",
    "\n",
    "# Data directories\n",
    "\n",
    "#coin_dataDir = 'DATA/TESTDIR/' # Debug dir for testing I/O logic and/or issues. It should be a clone of the above dir.\n",
    "model_dataDir = 'DATA/MODELDATA/'\n",
    "plot_dataDir = 'DATA/INITIAL_INSIGHTS/MOMENTUM_FACTORS/STATINFER/'\n",
    "model_plot_dataDir = 'DATA/MODELRESULTS/'\n",
    "\n",
    "# Time periods settings\n",
    "YEAR = 365\n",
    "\n",
    "# Helpers\n",
    "sns.set_style('darkgrid')\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# END GLOBAL SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc65e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "# Prediction vs Actual Scatter Plot\n",
    "def plot_preds_scatter(df, ticker=None):\n",
    "    if ticker is not None:\n",
    "        idx = pd.IndexSlice\n",
    "        df = df.loc[idx[ticker, :], :]\n",
    "    j = sns.jointplot(x='predicted', y='actuals',\n",
    "                      robust=True, ci=None,\n",
    "                      line_kws={'lw': 1, 'color': 'k'},\n",
    "                      scatter_kws={'s': 1},\n",
    "                      data=df,\n",
    "                      kind='reg')\n",
    "    j.ax_joint.yaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "    j.ax_joint.xaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda x, _: '{:.1%}'.format(x)))\n",
    "    j.ax_joint.set_xlabel('Predicted')\n",
    "    j.ax_joint.set_ylabel('Actuals')\n",
    "\n",
    "# Daily Information Coefficient(IC) Distribution\n",
    "def plot_ic_distribution(df, ax=None):\n",
    "    if ax is not None:\n",
    "        sns.distplot(df.ic, ax=ax)\n",
    "    else:\n",
    "        ax = sns.distplot(df.ic)\n",
    "    mean, median = df.ic.mean(), df.ic.median()\n",
    "    ax.axvline(0, lw=1, ls='--', c='k')\n",
    "    ax.text(x=.05, y=.9,\n",
    "            s=f'Mean: {mean:8.2f}\\nMedian: {median:5.2f}',\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center',\n",
    "            transform=ax.transAxes)\n",
    "    ax.set_xlabel('Information Coefficient')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Rolling Daily IC\n",
    "def plot_rolling_ic(df):\n",
    "    fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(14, 8))\n",
    "    rolling_result = df.sort_index().rolling(21).mean().dropna()\n",
    "    mean_ic = df.ic.mean()\n",
    "    rolling_result.ic.plot(ax=axes[0],\n",
    "                           title=f'Information Coefficient (Mean: {mean_ic:.2f})',\n",
    "                           lw=1)\n",
    "    axes[0].axhline(0, lw=.5, ls='-', color='k')\n",
    "    axes[0].axhline(mean_ic, lw=1, ls='--', color='k')\n",
    "\n",
    "    mean_rmse = df.rmse.mean()\n",
    "    rolling_result.rmse.plot(ax=axes[1],\n",
    "                             title=f'Root Mean Squared Error (Mean: {mean_rmse:.2%})',\n",
    "                             lw=1,\n",
    "                             ylim=(0, df.rmse.max()))\n",
    "    axes[1].axhline(df.rmse.mean(), lw=1, ls='--', color='k')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()   \n",
    "# END HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc2b9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in MDF with features\n",
    "model_mdf = pd.read_csv(model_dataDir + 'ModelData.csv')\n",
    "model_mdf.rename(columns={'Unnamed: 0': 'Dates'}, inplace=True)\n",
    "model_mdf['Dates'] = pd.to_datetime(model_mdf['Dates'])\n",
    "model_mdf.set_index(['Dates', 'Coin'], inplace=True)\n",
    "\n",
    "# Filter out 60 and 90d columns\n",
    "# Reason: Due to the relativly small size of the dataset, all the NaN values leave me with just 3 months of usable data.\n",
    "# I could impute the NaNs but for such long time periods, I think this is too risky and could lead to false models\n",
    "ninety_day_filter = model_mdf.filter(like='90d')\n",
    "#model_mdf = model_mdf.drop(ninety_day_filter.columns, axis=1)\n",
    "sixty_day_filter = model_mdf.filter(like='60d')\n",
    "#model_mdf = model_mdf.drop(sixty_day_filter.columns, axis=1)\n",
    "\n",
    "# Impute missing entries in the remaining data (max 30d period seems reasonable)\n",
    "model_mdf = model_mdf.groupby('Coin').apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f746d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs, OHLCV columns and lag period columns\n",
    "data = model_mdf\n",
    "\n",
    "data = (model_mdf\n",
    "            .dropna()\n",
    "            .drop(['Open', 'Close', 'Low', 'High'], axis=1))\n",
    "\n",
    "data = data.drop([c for c in data.columns if 'lag' in c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba747e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y values for the model\n",
    "y = data.filter(like='target')\n",
    "X = data.drop(y.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a284f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 30522 entries, (Timestamp('2020-01-01 00:00:00'), 'algorand') to (Timestamp('2022-01-14 00:00:00'), 'zcash')\n",
      "Data columns (total 29 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Volume      30522 non-null  float64\n",
      " 1   RSI         30522 non-null  float64\n",
      " 2   BB_high     30522 non-null  float64\n",
      " 3   BB_low      30522 non-null  float64\n",
      " 4   ATR         30522 non-null  float64\n",
      " 5   MACD        30522 non-null  float64\n",
      " 6   STOCH       30522 non-null  float64\n",
      " 7   ADX         30522 non-null  float64\n",
      " 8   DI_PLUS     30522 non-null  float64\n",
      " 9   DI_MINUS    30522 non-null  float64\n",
      " 10  return_1d   30522 non-null  float64\n",
      " 11  return_7d   30522 non-null  float64\n",
      " 12  return_14d  30522 non-null  float64\n",
      " 13  return_30d  30522 non-null  float64\n",
      " 14  return_60d  30522 non-null  float64\n",
      " 15  return_90d  30522 non-null  float64\n",
      " 16  year_2021   30522 non-null  int64  \n",
      " 17  year_2022   30522 non-null  int64  \n",
      " 18  month_2     30522 non-null  int64  \n",
      " 19  month_3     30522 non-null  int64  \n",
      " 20  month_4     30522 non-null  int64  \n",
      " 21  month_5     30522 non-null  int64  \n",
      " 22  month_6     30522 non-null  int64  \n",
      " 23  month_7     30522 non-null  int64  \n",
      " 24  month_8     30522 non-null  int64  \n",
      " 25  month_9     30522 non-null  int64  \n",
      " 26  month_10    30522 non-null  int64  \n",
      " 27  month_11    30522 non-null  int64  \n",
      " 28  month_12    30522 non-null  int64  \n",
      "dtypes: float64(16), int64(13)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#m\n",
    "drop_pca = data.filter(like='Principal')\n",
    "X = X.drop(drop_pca.columns, axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dec869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a custom implementation of TimeSeriesSplit CV from sklearn for finance data.\n",
    "# It is taken from code developed by Stefen Jansen and Marcos Lopez de Prado.\n",
    "# It is meant to eliminate any spill over between several train/test pairs derived from the dataset.\n",
    "# Financial data is especially suseptible to such leakage and so a custom TimeSeries CV approach is necessary.\n",
    "# The class below creates several train/test split pairs from the dataset and spearates them using\n",
    "# purging, embargoing, and Combinatorial CV techniques.\n",
    "\n",
    "class MultipleTimeSeriesCV:\n",
    "    \"\"\"Generates tuples of train_idx, test_idx pairs\n",
    "    Assumes the MultiIndex contains levels 'Coin' and 'Dates'\n",
    "    purges overlapping outcomes\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_splits=3,\n",
    "                 train_period_length=126,\n",
    "                 test_period_length=21,\n",
    "                 lookahead=None,\n",
    "                 shuffle=False):\n",
    "        self.n_splits = n_splits\n",
    "        self.lookahead = lookahead\n",
    "        self.test_length = test_period_length\n",
    "        self.train_length = train_period_length\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        unique_dates = X.index.get_level_values('Dates').unique()\n",
    "        days = sorted(unique_dates, reverse=True)\n",
    "\n",
    "        split_idx = []\n",
    "        for i in range(self.n_splits):\n",
    "            test_end_idx = i * self.test_length\n",
    "            test_start_idx = test_end_idx + self.test_length\n",
    "            train_end_idx = test_start_idx + + self.lookahead - 1\n",
    "            train_start_idx = train_end_idx + self.train_length + self.lookahead - 1\n",
    "            split_idx.append([train_start_idx, train_end_idx,\n",
    "                              test_start_idx, test_end_idx])\n",
    "\n",
    "        dates = X.reset_index()[['Dates']]\n",
    "        for train_start, train_end, test_start, test_end in split_idx:\n",
    "            train_idx = dates[(dates.Dates > days[train_start])\n",
    "                              & (dates.Dates <= days[train_end])].index\n",
    "            test_idx = dates[(dates.Dates > days[test_start])\n",
    "                             & (dates.Dates <= days[test_end])].index\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(list(train_idx))\n",
    "            yield train_idx, test_idx\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION MODELING\n",
    "\n",
    "# Cross Validation\n",
    "train_period_length = 30\n",
    "test_period_length = 7\n",
    "n_splits = int(2 * YEAR / test_period_length)\n",
    "lookahead = 1\n",
    "\n",
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead,\n",
    "                          train_period_length=train_period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b149b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and make predictions\n",
    "target = f'target_{lookahead}d'\n",
    "lr_predictions, lr_scores = [], []\n",
    "lr = LinearRegression()\n",
    "\n",
    "try:\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X), 1):\n",
    "       \n",
    "        X_train, y_train, = X.iloc[train_idx], y[target].iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y[target].iloc[test_idx]\n",
    "\n",
    "\n",
    "        lr.fit(X=X_train, y=y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "\n",
    "        preds = y_test.to_frame('actuals').assign(predicted=y_pred)\n",
    "        preds_by_day = preds.groupby(level='Dates')\n",
    "        scores = pd.concat([preds_by_day.apply(lambda x: spearmanr(x.predicted,\n",
    "                                                                   x.actuals)[0] * 100)\n",
    "                            .to_frame('ic'),\n",
    "                            preds_by_day.apply(lambda x: np.sqrt(mean_squared_error(y_pred=x.predicted,\n",
    "                                                                                    y_true=x.actuals)))\n",
    "                            .to_frame('rmse')], axis=1)\n",
    "\n",
    "        lr_scores.append(scores)\n",
    "        lr_predictions.append(preds)\n",
    "\n",
    "\n",
    "except IndexError:\n",
    "    print('Ran out of data to make more train/test splits')\n",
    "\n",
    "\n",
    "lr_scores = pd.concat(lr_scores)\n",
    "lr_predictions = pd.concat(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "lr_scores.to_hdf(f'{model_dataDir}lr_model_scores.h5', 'lr/scores')\n",
    "lr_predictions.to_hdf(f'{model_dataDir}lr_model_predictions.h5', 'lr/predictions')\n",
    "# Re-load results\n",
    "lr_scores = pd.read_hdf(f'{model_dataDir}lr_model_scores.h5', 'lr/scores')\n",
    "lr_predictions = pd.read_hdf(f'{model_dataDir}lr_model_predictions.h5', 'lr/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "lr_r, lr_p = spearmanr(lr_predictions.actuals, lr_predictions.predicted)\n",
    "print(f'Information Coefficient (overall): {lr_r:.3%} (p-value: {lr_p:.4%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preds_scatter(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ic_distribution(lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_ic(lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Ridge Regression\n",
    "ridge_alphas = np.logspace(-4, 4, 9)\n",
    "ridge_alphas = sorted(list(ridge_alphas) + list(ridge_alphas * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = int(2 * YEAR/test_period_length)\n",
    "train_period_length = 30\n",
    "test_period_length = 7\n",
    "lookahead = 1\n",
    "\n",
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead,\n",
    "                          train_period_length=train_period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = f'target_{lookahead}d'\n",
    "\n",
    "X = X.drop([c for c in X.columns if 'year' in c], axis=1)\n",
    "X = X.drop([c for c in X.columns if 'month' in c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6539ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation with Ridge\n",
    "ridge_coeffs, ridge_scores, ridge_predictions = {}, [], []\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    print(alpha, end=' ', flush=True)\n",
    "    start = time()\n",
    "    model = Ridge(alpha=alpha,\n",
    "                  fit_intercept=False,\n",
    "                  random_state=42)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)])\n",
    "\n",
    "    coeffs = []\n",
    "    \n",
    "    try:\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X), 1):\n",
    "            X_train, y_train, = X.iloc[train_idx], y[target].iloc[train_idx]\n",
    "            X_test, y_test = X.iloc[test_idx], y[target].iloc[test_idx]\n",
    "\n",
    "            pipe.fit(X=X_train, y=y_train)\n",
    "            y_pred = pipe.predict(X_test)\n",
    "\n",
    "            preds = y_test.to_frame('actuals').assign(predicted=y_pred)\n",
    "            preds_by_day = preds.groupby(level='Dates')\n",
    "            scores = pd.concat([preds_by_day.apply(lambda x: spearmanr(x.predicted,\n",
    "                                                                       x.actuals)[0] * 100)\n",
    "                                .to_frame('ic'),\n",
    "                                preds_by_day.apply(lambda x: np.sqrt(mean_squared_error(y_pred=x.predicted,\n",
    "                                                                                        y_true=x.actuals)))\n",
    "                                .to_frame('rmse')], axis=1)\n",
    "\n",
    "            ridge_scores.append(scores.assign(alpha=alpha))\n",
    "            ridge_predictions.append(preds.assign(alpha=alpha))\n",
    "\n",
    "            coeffs.append(pipe.named_steps['model'].coef_)\n",
    "            \n",
    "    except IndexError: \n",
    "        print('Ran out of data for train/test splits')\n",
    "        ridge_coeffs[alpha] = np.mean(coeffs, axis=0)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the ridge results\n",
    "ridge_scores = pd.concat(ridge_scores)\n",
    "ridge_scores.to_hdf(f'{model_dataDir}Ridge_Scores.h5', 'ridge/scores')\n",
    "\n",
    "ridge_coeffs = pd.DataFrame(ridge_coeffs, index=X.columns).T\n",
    "ridge_coeffs.to_hdf(f'{model_dataDir}Ridge_Coeffs.h5', 'ridge/coeffs')\n",
    "\n",
    "ridge_predictions = pd.concat(ridge_predictions)\n",
    "ridge_predictions.to_hdf(f'{model_dataDir}Ridge_Predictions.h5', 'ridge/predictions')\n",
    "\n",
    "#  Reload the data\n",
    "ridge_scores = pd.read_hdf(f'{model_dataDir}Ridge_Scores.h5', 'ridge/scores')\n",
    "ridge_coeffs = pd.read_hdf(f'{model_dataDir}Ridge_Coeffs.h5', 'ridge/coeffs')\n",
    "ridge_predictions = pd.read_hdf(f'{model_dataDir}Ridge_Predictions.h5', 'ridge/predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33852c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Ridge Results \n",
    "ridge_r, ridge_p = spearmanr(ridge_predictions.actuals, ridge_predictions.predicted)\n",
    "print(f'Information Coefficient (overall): {ridge_r:.3%} (p-value: {ridge_p:.4%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Alpha IC scores\n",
    "ridge_scores.groupby('alpha').ic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e035bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2735b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5be3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores[ridge_scores.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426221d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work around for 'ValueError: cannot reindex from a duplicate axis' error in the plot below\n",
    "ridge_scores['Dates'] = ridge_scores.index\n",
    "len_df = ridge_scores['alpha'].count()\n",
    "temp_new_index = [c for c in range(1,len_df + 1)]\n",
    "ridge_scores.index = temp_new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c64b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, sharex=True, figsize=(15, 5))\n",
    "\n",
    "scores_by_alpha = ridge_scores.groupby('alpha').ic.agg(['mean', 'median'])\n",
    "best_alpha_mean = scores_by_alpha['mean'].idxmax()\n",
    "best_alpha_median = scores_by_alpha['median'].idxmax()\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.lineplot(x='alpha',\n",
    "                  y='ic',\n",
    "                  data=ridge_scores,\n",
    "                  estimator=np.mean,\n",
    "                  label='Mean',\n",
    "                  ax=axes[0])\n",
    "\n",
    "scores_by_alpha['median'].plot(logx=True,\n",
    "                               ax=axes[0],\n",
    "                               label='Median')\n",
    "\n",
    "axes[0].axvline(best_alpha_mean,\n",
    "                ls='--',\n",
    "                c='k',\n",
    "                lw=1,\n",
    "                label='Max. Mean')\n",
    "axes[0].axvline(best_alpha_median,\n",
    "                ls='-.',\n",
    "                c='k',\n",
    "                lw=1,\n",
    "                label='Max. Median')\n",
    "axes[0].legend()\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[0].set_title('Cross Validation Performance')\n",
    "\n",
    "ridge_coeffs.plot(logx=True,\n",
    "                  legend=False,\n",
    "                  ax=axes[1],\n",
    "                  title='Ridge Coefficient Path')\n",
    "\n",
    "axes[1].axvline(best_alpha_mean,\n",
    "                ls='--',\n",
    "                c='k',\n",
    "                lw=1,\n",
    "                label='Max. Mean')\n",
    "axes[1].axvline(best_alpha_median,\n",
    "                ls='-.',\n",
    "                c='k',\n",
    "                lw=1,\n",
    "                label='Max. Median')\n",
    "axes[1].set_xlabel('Alpha')\n",
    "axes[1].set_ylabel('Coefficient Value')\n",
    "\n",
    "fig.suptitle('Ridge Results', fontsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the index back to DateTimeIndex\n",
    "ridge_scores.index = ridge_scores['Dates']\n",
    "ridge_scores.drop(['Dates'], axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be822a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = ridge_scores.groupby('alpha').ic.mean().idxmax()\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "plot_ic_distribution(ridge_scores[ridge_scores.alpha == best_alpha],\n",
    "                     ax=axes[0])\n",
    "axes[0].set_title('Daily Information Coefficients')\n",
    "top_coeffs = ridge_coeffs.loc[best_alpha].abs().sort_values().head(10).index\n",
    "top_coeffs.tolist()\n",
    "ridge_coeffs.loc[best_alpha, top_coeffs].sort_values().plot.barh(ax=axes[1],\n",
    "                                                                 title='Top 10 Coefficients')\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44948295",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_ic(ridge_scores[ridge_scores.alpha==best_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e36f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores.alpha.iloc[714:1428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a128fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Lasso Regression\n",
    "\n",
    "# CV parameters\n",
    "lasso_alphas = np.logspace(-10, -3, 8)\n",
    "\n",
    "train_period_length = 30\n",
    "test_period_length = 7\n",
    "YEAR = 365\n",
    "n_splits = int(2 * YEAR / test_period_length) # two years\n",
    "lookahead = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead,\n",
    "                          train_period_length=train_period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Cross-validation\n",
    "target = f'target_{lookahead}d'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = X.drop([c for c in X.columns if 'year' in c], axis=1)\n",
    "X = X.drop([c for c in X.columns if 'month' in c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coeffs, lasso_scores, lasso_predictions = {}, [], []\n",
    "for alpha in lasso_alphas:\n",
    "    print(alpha, end=' ', flush=True)\n",
    "    model = Lasso(alpha=alpha,\n",
    "                  fit_intercept=False,  # StandardScaler centers data\n",
    "                  random_state=42,\n",
    "                  tol=1e-3,\n",
    "                  max_iter=1000,\n",
    "                  warm_start=True,\n",
    "                  selection='random')\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)])\n",
    "    coeffs = []\n",
    "    \n",
    "    try:\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X), 1):\n",
    "            t = time()\n",
    "            X_train, y_train, = X.iloc[train_idx], y[target].iloc[train_idx]\n",
    "            X_test, y_test = X.iloc[test_idx], y[target].iloc[test_idx]\n",
    "\n",
    "            pipe.fit(X=X_train, y=y_train)\n",
    "            y_pred = pipe.predict(X_test)\n",
    "\n",
    "            preds = y_test.to_frame('actuals').assign(predicted=y_pred)\n",
    "            preds_by_day = preds.groupby(level='Dates')\n",
    "            scores = pd.concat([preds_by_day.apply(lambda x: spearmanr(x.predicted,\n",
    "                                                                       x.actuals)[0] * 100)\n",
    "                                .to_frame('ic'),\n",
    "                                preds_by_day.apply(lambda x: np.sqrt(mean_squared_error(y_pred=x.predicted,\n",
    "                                                                                        y_true=x.actuals)))\n",
    "                                .to_frame('rmse')],\n",
    "                               axis=1)\n",
    "\n",
    "            lasso_scores.append(scores.assign(alpha=alpha))\n",
    "            lasso_predictions.append(preds.assign(alpha=alpha))\n",
    "\n",
    "            coeffs.append(pipe.named_steps['model'].coef_)\n",
    "    except IndexError: \n",
    "        print('Ran out of data for train/test splits')\n",
    "        lasso_coeffs[alpha] = np.mean(coeffs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac90fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist Lasso outputs\n",
    "lasso_scores = pd.concat(lasso_scores)\n",
    "lasso_scores.to_hdf(f'{model_dataDir}Lasso_Scores.h5', 'lasso/scores')\n",
    "\n",
    "lasso_coeffs = pd.DataFrame(lasso_coeffs, index=X.columns).T\n",
    "lasso_coeffs.to_hdf(f'{model_dataDir}Lasso_Coeffs.h5', 'lasso/coeffs')\n",
    "\n",
    "lasso_predictions = pd.concat(lasso_predictions)\n",
    "lasso_predictions.to_hdf(f'{model_dataDir}Lasso_Predictions.h5', 'lasso/predictions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39dacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "best_alpha = lasso_scores.groupby('alpha').ic.mean().idxmax()\n",
    "preds = lasso_predictions[lasso_predictions.alpha==best_alpha]\n",
    "\n",
    "lasso_r, lasso_p = spearmanr(preds.actuals, preds.predicted)\n",
    "print(f'Information Coefficient (overall): {lasso_r:.3%} (p-value: {lasso_p:.4%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores.groupby('alpha').ic.agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work around for 'ValueError: cannot reindex from a duplicate axis' error in the plot below\n",
    "lasso_scores['Dates'] = lasso_scores.index\n",
    "len_df = lasso_scores['alpha'].count()\n",
    "temp_new_index = [c for c in range(1,len_df + 1)]\n",
    "lasso_scores.index = temp_new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b55d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Coefficient paths\n",
    "fig, axes = plt.subplots(ncols=2, sharex=True, figsize=(15, 5))\n",
    "\n",
    "scores_by_alpha = lasso_scores.groupby('alpha').ic.agg(['mean', 'median'])\n",
    "best_alpha_mean = scores_by_alpha['mean'].idxmax()\n",
    "best_alpha_median = scores_by_alpha['median'].idxmax()\n",
    "\n",
    "ax = sns.lineplot(x='alpha', y='ic', data=lasso_scores, estimator=np.mean, label='Mean', ax=axes[0])\n",
    "\n",
    "scores_by_alpha['median'].plot(logx=True, ax=axes[0], label='Median')\n",
    "\n",
    "axes[0].axvline(best_alpha_mean, ls='--', c='k', lw=1, label='Max. Mean')\n",
    "axes[0].axvline(best_alpha_median, ls='-.', c='k', lw=1, label='Max. Median')\n",
    "axes[0].legend()\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[0].set_title('Cross Validation Performance')\n",
    "\n",
    "lasso_coeffs.plot(logx=True, legend=False, ax=axes[1], title='Lasso Coefficient Path')\n",
    "axes[1].axvline(best_alpha_mean, ls='--', c='k', lw=1, label='Max. Mean')\n",
    "axes[1].axvline(best_alpha_median, ls='-.', c='k', lw=1, label='Max. Median')\n",
    "axes[1].set_xlabel('Alpha')\n",
    "axes[1].set_ylabel('Coefficient Value')\n",
    "\n",
    "fig.suptitle('Lasso Results', fontsize=14)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.9)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57728a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the index back to DateTimeIndex\n",
    "lasso_scores.index = lasso_scores['Dates']\n",
    "lasso_scores.drop(['Dates'], axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = lasso_scores.groupby('alpha').ic.mean().idxmax()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "plot_ic_distribution(lasso_scores[lasso_scores.alpha==best_alpha], ax=axes[0])\n",
    "axes[0].set_title('Daily Information Coefficients')\n",
    "\n",
    "top_coeffs = lasso_coeffs.loc[best_alpha].abs().sort_values().head(10).index\n",
    "top_coeffs.tolist()\n",
    "lasso_coeffs.loc[best_alpha, top_coeffs].sort_values().plot.barh(ax=axes[1], title='Top 10 Coefficients')\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82477117",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_ic(lasso_scores[lasso_scores.alpha==best_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "best_ridge_alpha = ridge_scores.groupby('alpha').ic.mean().idxmax()\n",
    "best_ridge_preds = ridge_predictions[ridge_predictions.alpha==best_ridge_alpha]\n",
    "best_ridge_scores = ridge_scores[ridge_scores.alpha==best_ridge_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44df0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso_alpha = lasso_scores.groupby('alpha').ic.mean().idxmax()\n",
    "best_lasso_preds = lasso_predictions[lasso_predictions.alpha==best_lasso_alpha]\n",
    "best_lasso_scores = lasso_scores[lasso_scores.alpha==best_lasso_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([lr_scores.assign(Model='Linear Regression'),\n",
    "               best_ridge_scores.assign(Model='Ridge Regression'),\n",
    "               best_lasso_scores.assign(Model='Lasso Regression')]).drop('alpha', axis=1)\n",
    "df.columns = ['IC', 'RMSE', 'Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.groupby('Model').IC.agg(['mean', 'median'])\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14,4), sharey=True, sharex=True)\n",
    "\n",
    "scores['mean'].plot.barh(ax=axes[0], xlim=(0.85, 20), title='Mean')\n",
    "scores['median'].plot.barh(ax=axes[1], xlim=(0.8, 20.1), title='Median')\n",
    "axes[0].set_xlabel('Daily IC')\n",
    "axes[1].set_xlabel('Daily IC')\n",
    "\n",
    "fig.suptitle('Daily Information Coefficient by Model', fontsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acca67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
